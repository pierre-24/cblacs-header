{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ScaLAPACKe","text":"<p>Provide a set of headers and wrappers in order to easily use scaLAPACK (and its components, PBLAS and BLACS) in C. Unlike LAPACKe, it is not a Fortran to C translation, rather a set of lightweight wrappers.</p> <p>More info here.</p>"},{"location":"#installation","title":"Installation","text":"<p>See there.</p>"},{"location":"#usage","title":"Usage","text":"<p>to be added later.</p>"},{"location":"about/","title":"About this project","text":"<p>TL;DR: This project, developed by Pierre Beaujean, provides C headers (missing in the reference scaLAPACK implementation) and C wrappers (similar in spirit to LAPACKe).</p>"},{"location":"about/#overview","title":"Overview","text":""},{"location":"about/#motivation","title":"Motivation","text":"<p>Using scaLAPACK directly in C presents several challenges:</p> <ul> <li>Lack of C Headers: The reference scaLAPACK implementation does not include a comprehensive set of C headers, apart from those available through oneMKL.</li> <li>Absence of a Higher-Level Interface: Unlike BLAS and LAPACK, scaLAPACK lacks a middle- or high-level C interface.</li> <li>Limited Documentation: Detailed usage information is often only accessible by diving into the source code, as official documentation is sparse.</li> </ul> <p>This project addresses the first two issues by providing:</p> <ul> <li>A set of C headers for scaLAPACK.</li> <li>A low- and middle-level interface to PBLAS, BLACS, and nearly all scaLAPACK functions.</li> </ul> <p>The third issue (documentation) remains an ongoing challenge, reflecting a broader trend in netlib's projects that rely heavily on aging user guides and systematic function design.</p> <p>Note: This project is in its early stages, and the API is not yet stable and may undergo changes.</p> <p>For more information on how to use scaLAPACKe in practice, including common caveats, refer to the Quickstart Guide. A more beginner-friendly introduction to (sca)LAPACK(e) is also available here.</p>"},{"location":"about/#alternatives","title":"Alternatives","text":"<p>Currently, there are no direct alternatives to this project that allow for using scaLAPACK in C, other than the aforementioned headers provided by oneMKL (<code>mkl_{blacs,pblas,scalapack}.h</code>). If such an alternative existed, this project likely wouldn't.</p> <p>However, SLATE, written in C++, aims to replace scaLAPACK and is worth considering. There is also an (undocumented?) C API, which appears to be auto-generated. Additionally, with the rise of GPUs, other projects with different approaches have emerged.</p> <p>Other libraries interface with or expose LAPACK functions (though not scaLAPACK), including those in languages like Python (e.g., SciPy). See Wikipedia for more details.</p>"},{"location":"about/#implementation","title":"Implementation","text":"<p>The files are generated using a Python script, with manual adjustments made as needed.</p> <p>Interested in contributing? Check out our contribution guidelines!</p>"},{"location":"about/#about-me","title":"About me","text":"<p>I'm Pierre Beaujean, a Ph.D. in quantum chemistry from the University of Namur (Belgium), and the main (and only) developer of this project. My goal is to leverage scaLAPACK(e) to overcome the computational and memory limitations of a single computer node.</p> <p>I have no affiliation with netlib, MKL, or similar projects, and I'm not an expert in scaLAPACK.  I'm just someone who needed this functionality in C and decided to share my solution with the world. \ud83d\ude09</p>"},{"location":"contrib/CONTRIBUTING/","title":"Install and contribute","text":""},{"location":"contrib/CONTRIBUTING/#install-for-contributors","title":"Install (for contributors)","text":"<p>If you only want to use scaLAPACKe in your project, you should rather check this page.</p> <p>You should preliminarily check that you have:</p> <ol> <li>A working MPI library and compiler (generally referred to as <code>mpicc</code>),</li> <li>The Meson build system, with a backend (generally ninja). This is probably available in you package manager.</li> <li>A linear algebra backend which provides scaLAPACK (netlib, MKL, AOCL, etc).</li> </ol> <p>The first step is to fork the repository and clone your fork:</p> <pre><code>git clone https://github.com/YOUR_USERNAME/scalapacke.git\ncd scalapacke\n</code></pre> <p>Few tools that are used to manage this project are written in or use Python. It is therefore a good idea to install them:</p> <pre><code># virtualenv\npython -m venv venv\nsource venv/bin/activate\nmake install-dev  # or pip install -e .[dev]\n</code></pre> <p>Note that all other commands in this documentation assume that you have activated the virtualenv :)</p>"},{"location":"contrib/CONTRIBUTING/#contribute","title":"Contribute","text":"<p>Contributions, either with issues or pull requests are welcomed.</p> <p>Some tips:</p> <ul> <li> <p>Before contributing, check the contributors' notes.</p> </li> <li> <p>A good place to start is the list of issues.   In fact, it is easier if you start by filling an issue, and if you want to work on it, says so there, so that everyone knows that the issue is handled.</p> </li> <li> <p>Don't forget to work on a separate branch.   Since this project follow the git flow, you should base your branch on <code>dev</code>, not work in it directly:</p> <pre><code>git checkout -b new_branch origin/dev\n</code></pre> </li> <li> <p>Don't forget to regularly run the linting (for python) and tests (for the library):</p> <pre><code>make lint\nmeson test -C _build/\n</code></pre> <p>Indeed, the code follows the PEP-8 style recommendations, checked by <code>flake8</code>, for the python part. Having an extensive test suite is also a good idea to prevent regressions.</p> </li> <li> <p>If you want to see and edit the doc, you can run the <code>mkdocs</code> webserver:</p> <pre><code>mkdocs serve\n</code></pre> </li> <li> <p>Pull requests should be unitary, and include unit test(s) and documentation if needed.   The test suite and lint must succeed for the merge request to be accepted.</p> </li> </ul>"},{"location":"contrib/notes/","title":"Contributors' Notes","text":"<p>Here are some important notes to help you contribute to the project efficiently :)</p>"},{"location":"contrib/notes/#project-architecture","title":"Project Architecture","text":"<p>The project is organized into three main parts:</p> <ol> <li> <p>Headers and C Wrappers: Located in the <code>include/</code> and <code>src/</code> directories, respectively.    These files are partially tested, with tests found in the <code>tests/</code> directory.</p> </li> <li> <p>Repository Management Scripts:    Located in the <code>scripts/</code> directory, these scripts help manage various aspects of the repository.</p> </li> <li> <p>Python Scripts for Code Generation:    Located in the <code>scalapacke_files_create/</code> directory, these scripts assist in generating the headers and wrapper files.</p> </li> </ol> <p>The primary build tool used is the Meson build system, which facilitates both building the library and running tests.</p>"},{"location":"contrib/notes/#c-files","title":"C Files","text":"<p>Currently, the C files are auto-generated (see below) with no human intervention.  As a result, they might not be very human-friendly.</p>"},{"location":"contrib/notes/#repository-management-scripts","title":"Repository Management Scripts","text":"<ul> <li> <p><code>scripts/package_it.yml</code>: Used by the GitHub Action responsible for creating a Meson wrap file for each release.    You can run it manually to verify everything is functioning correctly.</p> </li> <li> <p><code>scripts/release_it.sh</code>: A script that uses <code>bump2version</code> to increment the version number across the project and trigger the creation of a new release.    It is probably not advisable to run this script unless you have the appropriate permissions on the repository.</p> </li> </ul>"},{"location":"contrib/notes/#python-scripts","title":"Python Scripts","text":"<ul> <li><code>scaLAPACKe_create</code>: A script that generates the headers and wrappers, based on the scaLAPACK reference repository.</li> </ul> <p>Warning</p> <p>The generated files should not be blindly copied into <code>src/</code> and <code>include/</code>.  Although the script is designed to produce results similar to those already in the repository, there might be manual optimizations or bug fixes in place.  Proceed with caution!</p> <p>The workflow is something like:</p> <pre><code># create a temporary directory\nmkdir tmp\ncd tmp\n\n# clone scalapack in it\ngit clone https://github.com/Reference-ScaLAPACK/scalapack.git\n\n# create files\nscaLAPACKe_create --all ./scalapack\n</code></pre>"},{"location":"contrib/notes/#about-tests","title":"About tests","text":"<p>Between package managers, the module system or ... Other things, it is sometimes difficult to have a proper environment.  Thus, any help on writing proper tests is welcomed :)</p>"},{"location":"dev/install/","title":"Installing scaLAPACKe","text":"<p>To install scaLAPACKe, you'll need two key components: an MPI library implementation and a scaLAPACK implementation.</p> <p>Popular MPI options include:</p> <ul> <li>OpenMPI</li> <li>MPICH</li> <li>Other implementations (most are derivatives of the above)</li> </ul> <p>For scaLAPACK, consider the following:</p> <ul> <li>Netlib scaLAPACK (the reference implementation)</li> <li>oneMKL</li> <li>AOCL</li> <li>Other implementations (usually based on netlib's version)</li> </ul> <p>Check your package manager or module system, as some of these libraries might already be available on your system.</p>"},{"location":"dev/install/#using-the-files-in-your-project","title":"Using the files in your project","text":"<p>To use scaLAPACKe in your project, follow these steps:</p> <ol> <li>Download the latest release.</li> <li>Extract the contents of the <code>src/</code> and <code>include/</code> directories to a suitable location within your project.</li> </ol> <p>Make sure to:</p> <ul> <li>Add the extracted files to your build system (e.g., Makefile, CMake).</li> <li>Use <code>mpicc</code> (or an equivalent MPI compiler wrapper) to compile your project.</li> <li>Link against the scaLAPACK library of your choice.</li> <li>If using 64-bit integers (ILP64), redefine <code>lapack_int</code> with <code>-Dlapack_int='long long int'</code> in your compiler options.    Learn more about ILP64 here.</li> </ul>"},{"location":"dev/install/#with-meson-in-your-project-recommended","title":"With Meson, in your project (recommended)","text":"<p>If you use Meson in your project, this projects provide a ready-to-go archive and a corresponding wrap files. Just grab the wrap file corresponding to the version you want to use ...</p> <pre><code># in your super project root folder\n\n# create a `subprojects` folder if it does not exists yet\nmkdir -p subprojects\n\n# download wrap file\nwget https://github.com/pierre-24/scalapacke/releases/download/v0.2.2/scalapacke_v0.2.2.wrap -O subprojects/scalapacke.wrap\n</code></pre> <p>... and add something like this in your <code>meson.build</code>:</p> <pre><code>scalapacke_dep = cc.find_library('scalapacke', required: false)\nif not scalapacke_dep.found()\n  scalapacke_proj = subproject('scalapacke', default_options: ['la_backend=scalapack'])\n  scalapacke_dep = scalapacke_proj.get_variable('scalapacke_dep')\nendif\nproject_dep += scalapacke_dep\n</code></pre> <p>Note: Don't forget to set <code>CC=mpicc</code> (or others) before any <code>meson</code> command, otherwise it will not use MPI.</p> <p>You can configure the project by adjusting the options found in the <code>meson_options.txt</code> file. Here's a quick overview:</p> <ul> <li><code>la_backend</code>: Select the linear algebra backend, either by specifying a <code>pkg-config</code> file or setting it to <code>custom</code>.</li> <li><code>mkl_mpi</code>: Choose the MPI implementation to use (relevant only for MKL).</li> <li><code>la_libraries</code>: Manually specify a list of libraries (relevant only if <code>la_backend=custom</code>).</li> <li><code>ilp64</code>: Enable 64-bit integers.</li> </ul> <p>To successfully build the project, you must either provide a value for <code>la_backend</code> or set <code>la_backend=custom</code> and define <code>la_libraries</code>.</p>"},{"location":"dev/install/#detailed-options-description","title":"Detailed options' description","text":"<p>The simplest way to configure scaLAPACKe is by setting <code>la_backend</code> to a valid <code>pkg-config</code> file, if supported by your OS. To find available options, run:</p> <pre><code>pkg-config --list-all | grep scalapack\n</code></pre> <p>For example, on Ubuntu 24.04, something like <code>default_options: ['la_backend=scalapack-openmpi']</code> should be used. Note that this generally force the choice of an MPI implementation as well.</p> <p>This generally also selects an MPI implementation.</p> <p>If you're using oneMKL, Intel provides several <code>pkg-config</code> files, as detailed here.  However, these files don't include scaLAPACK, so our <code>meson.build</code> script requires an additional <code>mkl_mpi</code> option, which can be set to <code>openmpi</code> or <code>intelmpi</code> (equivalent to <code>mpich</code>).  An example configuration might be: <code>default_options: ['la_backend=mkl-static-lp64-seq', 'mkl_mpi=openmpi']</code>.</p> <p>For custom or non-standard libraries (like AOCL) without a <code>pkg-config</code> file, set <code>la_backend=custom</code> and specify the libraries using <code>la_libraries=lib1,lib2,...</code>.  Meson will attempt to locate them.  Ensure that your <code>LIBRARY_PATH</code> is correctly set by exporting it if necessary: </p> <pre><code>export LIBRARY_PATH=$LIBRARY_PATH:/path/to/your/library/\n</code></pre> <p>If you want to use 64-bits integers (if and only if your scaLAPACK implementation supports it), add <code>ilp64=true</code>.</p>"},{"location":"dev/install/#tested-builds","title":"Tested builds","text":"<p>In our test suite, we cover the following test cases:</p> Linear algebra library MPI flavor Can use ILP64? Netlib scaLAPACK OpenMPI No (ILP64 version not available as a Ubuntu package) MKL scaLAPACK OpenMPI or Intel MPI Yes (<code>la_backend=mkl-static-ilp64-seq</code>) and no (<code>la_backend=mkl-static-lp64-seq</code>) AOCL (with <code>la_backend=custom</code> and <code>la_libraires=scalapack</code>) OpenMPI No (and probably yes, using <code>$AOCLROOT/set_aocl_interface_symlink.sh ilp64</code>, but unstable, see #3) <p>Feel free to suggest modifications to this table with your discoveries :)</p>"},{"location":"dev/install/#with-meson-in-your-system","title":"With meson, in your system","text":"<p>If you want to install the library in your system, then:</p> <pre><code># clone this repository\ngit clone https://github.com/pierre-24/scalapacke.git\ncd scalapacke\n\n# setup (don't forget to set the different options)\nexport CC=mpicc\nmeson setup _build  # /!\\ see below\n\n# compile\nmeson compile -C _build\n\n# (optional) tests\nmeson configure _build -Dtests=true -Dtests_nprocs=2\nmeson test -C _build\n\n# install\nmeson configure _build --prefix=$HOME/.local\nmeson install -C _build\n</code></pre> <p>Note that any of the option discussed in the previous section should be added to the <code>meson setup</code> line, prefixed by <code>-D</code>, e.g., <code>-Dla_backend=scalapack-openmpi</code>, <code>-Dilp64=true</code>, etc.</p>"},{"location":"dev/quickstart/","title":"Quickstart into production","text":"<p>Info</p> <p>This guide assumes you're already familiar with scaLAPACK and are looking to use the C wrappers provided by scaLAPACKe.  If you're new to scaLAPACK, please check out the tutorial instead.</p> <p>Currently, scaLAPACKe offers both a low-level and a middle-level interface.  The main difference between the two is that the middle-level interface uses pass-by-value for arguments.</p>"},{"location":"dev/quickstart/#common-features-and-caveats-for-both-interfaces","title":"Common Features and Caveats for Both Interfaces","text":"<ul> <li> <p>Variables of Fortran type <code>INTEGER</code> and <code>LOGICAL</code> are converted to <code>lapack_int</code> in scaLAPACKe.    This conversion supports the use of 64-bit integers through the ILP64 programming model.</p> </li> <li> <p>Variables of Fortran type <code>COMPLEX</code> and <code>COMPLEX*16</code> are converted to <code>float*</code> and <code>double*</code>, respectively.</p> </li> <li> <p>Arrays are passed as pointers, not as pointers to pointers.    They should be stored in Fortran style, i.e., column-major order: for an <code>MxN</code> matrix (where <code>M</code> is the number of rows and <code>N</code> is the number of columns), <code>A(i,j)</code> is accessed as <code>A[i + j * LDA]</code>, where <code>LDA</code> is the leading dimension of <code>A</code> (typically the number of rows, <code>M</code>).</p> </li> <li> <p>Similarly, strings are passed as pointers, not as pointers to pointers.    Generally, only the first character of the string is significant.</p> </li> <li> <p>When an argument (or return value) refers to a row or column number, 1-based indexing is used (i.e., <code>1 &lt;= i &lt;= N</code> rather than <code>0 &lt;= i &lt; N</code>).</p> </li> </ul> <p>Warning</p> <p>Currently, scaLAPACKe does not provide a mechanism to switch from row-major to column-major storage, unlike LAPACKe. Implementing this would incur significant overhead due to the need to redistribute data across all processes.  Therefore, it is recommended to use column-major arrays when working with scaLAPACKe functions.</p> <p>Remember that memory locality is crucial for performance, so you should adapt your code when looping over array values:</p> <pre><code>// A is an MxN array\nfor (int j = 0; j &lt; N; j++) { // loop over columns\n    for (int i = 0; i &lt; M; i++) // loop over rows\n        // use `A[i + j * LDA]` for `A(i, j)`.  \n}\n</code></pre>"},{"location":"dev/quickstart/#the-low-level-interface","title":"The low-level interface","text":"<p>The low-level interface requires three of the header files provided by scaLAPACKe: <code>blacs.h</code>, <code>pblas.h</code>, and <code>scalapack.h</code>.</p> <p>This interface follows the customary naming convention for Fortran-C interfaces: the Fortran routine name is converted to lowercase, with an underscore (<code>_</code>) appended at the end.  For example, the Fortran subroutine <code>PDGEMM</code> becomes <code>pdgemm_</code>.</p> <p>All arguments from the original Fortran subroutine are retained and must be passed as pointers, rather than by value.</p> Example <p>The following code:</p> <ol> <li>Generates two matrices, \\(A\\) and \\(I\\), whith \\(I_{ij} = \\delta_{ij}\\).    \\(A\\) is filled with random numbers.</li> <li>It computes \\(C = A\\times I\\) and then \\(A = C \\times I - A\\).    At the end of this operation, \\(A_{ij} = 0\\).</li> <li>It prints \\(\\max\\{A_{ij}\\}\\) (which should be zero) and exits.</li> </ol> <pre><code>#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;time.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n\n#include &lt;blacs.h&gt;\n#include &lt;pblas.h&gt;\n#include &lt;scalapack.h&gt;\n\nlapack_int I_ZERO = 0, I_ONE = 1;\ndouble D_ONE = 1.0, D_ZERO = 0.0, D_M_ONE = -1.f;\n\nint main(int argc, char* argv[]) {\n    lapack_int N = 128, blk_size = 16;\n    lapack_int nprocs, ctx_sys, grid_M, grid_N, glob_i, glob_j;\n    lapack_int  iam, loc_row, loc_col, loc_M, loc_N, loc_LD, info;\n    lapack_int desc_A[9];\n    double *A, *I, *C; // A, I, and C are NxN matrices\n\n    // seed\n    srand(time(NULL));\n\n    // initialize BLACS &amp; system context\n    blacs_pinfo_(&amp;iam, &amp;nprocs);\n    blacs_get_(&amp;I_ZERO, &amp;I_ZERO, &amp;ctx_sys);\n\n    // create a (grid_M x grid_N) grid\n    grid_M = sqrt((double) nprocs);\n    grid_N = nprocs / grid_M;\n    blacs_gridinit_(&amp;ctx_sys, \"R\", &amp;grid_M, &amp;grid_N);\n    blacs_gridinfo_(&amp;ctx_sys, &amp;grid_M, &amp;grid_N, &amp;loc_row, &amp;loc_col);\n\n    if(loc_row &gt;= 0 &amp;&amp; loc_col &gt;= 0) { // if I'm in grid\n        loc_M = numroc_(&amp;N, &amp;blk_size, &amp;loc_row, &amp;I_ZERO, &amp;grid_M);\n        loc_N = numroc_(&amp;N, &amp;blk_size, &amp;loc_col, &amp;I_ZERO, &amp;grid_N);\n\n        loc_LD =  loc_M;\n        A = calloc(loc_M * loc_N, sizeof(double));\n        I = calloc(loc_M * loc_N, sizeof(double));\n        C = calloc(loc_M * loc_N, sizeof(double));\n\n        // fill arrays locally\n        for(lapack_int loc_j=1; loc_j &lt;= loc_N; loc_j++) {\n            glob_j = indxl2g_(&amp;loc_j, &amp;blk_size, &amp;loc_col, &amp;I_ZERO, &amp;grid_N);\n            for(lapack_int loc_i=1; loc_i &lt;= loc_M; loc_i++) { // set A[i,j]\n                glob_i = indxl2g_(&amp;loc_i, &amp;blk_size, &amp;loc_row, &amp;I_ZERO, &amp;grid_M);\n                A[(loc_j-1) * loc_LD + (loc_i-1)] = ((double) rand()) / INT_MAX;\n                I[(loc_j-1) * loc_LD + (loc_i-1)] = (glob_i == glob_j);\n            }\n        }\n\n        // create descriptor for A, I and C\n        descinit_(desc_A,\n                  &amp;N, &amp;N, &amp;blk_size, &amp;blk_size,\n                  &amp;I_ZERO, &amp;I_ZERO, &amp;ctx_sys,\n                  &amp;loc_LD, &amp;info);\n\n        // compute C = A * I\n        pdgemm_(\"N\", \"N\", &amp;N, &amp;N, &amp;N,\n                &amp;D_ONE, A, &amp;I_ONE, &amp;I_ONE, desc_A,\n                I, &amp;I_ONE, &amp;I_ONE, desc_A,\n                &amp;D_ZERO, C, &amp;I_ONE, &amp;I_ONE, desc_A\n        );\n\n        // compute A = C * I - A\n        pdgemm_(\"N\", \"N\", &amp;N, &amp;N, &amp;N,\n                &amp;D_ONE, C, &amp;I_ONE, &amp;I_ONE, desc_A,\n                I, &amp;I_ONE, &amp;I_ONE, desc_A,\n                &amp;D_M_ONE, A, &amp;I_ONE, &amp;I_ONE, desc_A\n        );\n\n        // fetch the maximum (i.e., the 1-norm)\n        double* work = (double*) calloc(loc_LD, sizeof(double));\n        double max = pdlange_( \"1\", &amp;N, &amp;N, A, &amp;I_ONE, &amp;I_ONE, desc_A, work);\n\n        if(iam == 0)\n            printf(\"%f\\n\", max);\n\n        free(A);\n        free(I);\n        free(C);\n        free(work);\n    }\n\n    blacs_exit_(&amp;I_ZERO);\n    return EXIT_SUCCESS;\n}\n</code></pre> <p>Notice that both <code>loc_i</code> and <code>loc_j</code> starts at one.</p>"},{"location":"dev/quickstart/#the-middle-level-interface","title":"The middle-level interface","text":"<p>The middle-level interface requires all the header and C files provided by scaLAPACKe.</p> <p>The naming convention for this interface is as follows: take the Fortran routine name, convert it to lowercase, and prepend it with <code>SCALAPACKE_</code>.  For example, the Fortran routine <code>PDGEMM</code> becomes <code>SCALAPACKE_pdgemm</code>.</p> <p>The <code>INFO</code> parameter found in the Fortran subroutine is omitted in scaLAPACKe.  Instead, the <code>lapack_int</code> return value of the function is set to the value that <code>INFO</code> would have returned. All other arguments from the original Fortran subroutine are retained in the C interface.</p> <p>Arguments are passed by value rather than by pointer when both of the following conditions are met:</p> <ol> <li>The argument is input-only.</li> <li>The argument is a scalar type (such as <code>INTEGER</code>, <code>REAL</code>, <code>DOUBLE</code>, or <code>LOGICAL</code>).</li> </ol> Example <p>This is the same program as above, but written using the middle-level interface:</p> <pre><code>#include &lt;stdlib.h&gt;\n#include &lt;string.h&gt;\n#include &lt;time.h&gt;\n#include &lt;limits.h&gt;\n#include &lt;math.h&gt;\n#include &lt;stdio.h&gt;\n\n#include &lt;scalapacke_blacs.h&gt;\n#include &lt;scalapacke_pblas.h&gt;\n#include &lt;scalapacke.h&gt;\n\nint main(int argc, char* argv[]) {\n    lapack_int N = 128, blk_size = 16;\n    lapack_int nprocs, ctx_sys, grid_M, grid_N, glob_i, glob_j;\n    lapack_int  iam, loc_row, loc_col, loc_M, loc_N, loc_LD, info;\n    lapack_int desc_A[9];\n    double *A, *I, *C; // A, I, and C are NxN matrices\n\n    // seed\n    srand(time(NULL));\n\n    // initialize BLACS &amp; system context\n    SCALAPACKE_blacs_pinfo(&amp;iam, &amp;nprocs);\n    SCALAPACKE_blacs_get(0, 0, &amp;ctx_sys);\n\n    // create a (grid_M x grid_N) grid\n    grid_M = sqrt((double) nprocs);\n    grid_N = nprocs / grid_M;\n    blacs_gridinit_(&amp;ctx_sys, \"R\", &amp;grid_M, &amp;grid_N);\n    blacs_gridinfo_(&amp;ctx_sys, &amp;grid_M, &amp;grid_N, &amp;loc_row, &amp;loc_col);\n\n    if(loc_row &gt;= 0) { // if I'm in grid\n        loc_M = SCALAPACKE_numroc(N, blk_size, loc_row, 0, grid_M);\n        loc_N = SCALAPACKE_numroc(N, blk_size, loc_col, 0, grid_N);\n\n        loc_LD =  loc_M;\n        A = calloc(loc_M * loc_N, sizeof(double));\n        I = calloc(loc_M * loc_N, sizeof(double));\n        C = calloc(loc_M * loc_N, sizeof(double));\n\n        // fill arrays locally\n        for(lapack_int loc_j=0; loc_j &lt; loc_N; loc_j++) {\n            glob_j = SCALAPACKE_indxl2g(loc_j + 1, blk_size, loc_col, 0, grid_N);\n            for(lapack_int loc_i=0; loc_i &lt; loc_M; loc_i++) { // set A[i,j]\n                glob_i = SCALAPACKE_indxl2g(loc_i + 1, blk_size, loc_row, 0, grid_M) ;\n                A[loc_j * loc_LD + loc_i] = ((double) rand()) / INT_MAX;\n                I[loc_j * loc_LD + loc_i] = (glob_i == glob_j);\n            }\n        }\n\n        // create descriptor for A, I and C\n        SCALAPACKE_descinit(desc_A,\n                            N, N, blk_size, blk_size,\n                            0, 0, ctx_sys,\n                            loc_LD);\n\n        // compute C = A * I\n        SCALAPACKE_pdgemm(\"N\", \"N\", N, N, N,\n                          1., A, 1, 1, desc_A,\n                          I, 1, 1, desc_A,\n                          .0, C, 1, 1, desc_A\n        );\n\n        // compute A = C * I - A\n        SCALAPACKE_pdgemm(\"N\", \"N\", N, N, N,\n                          1., C, 1, 1, desc_A,\n                          I, 1, 1, desc_A,\n                          -1., A, 1, 1, desc_A\n        );\n\n        // fetch the maximum (i.e., the 1-norm)\n        double* work = (double*) calloc(loc_LD, sizeof(double));\n        double max = SCALAPACKE_pdlange( \"1\", N, N, A, 1, 1, desc_A, work);\n\n        if(iam == 0)\n            printf(\"%f\\n\", max);\n\n        free(A);\n        free(I);\n        free(C);\n        free(work);\n    }\n\n    SCALAPACKE_blacs_exit(0);\n    return EXIT_SUCCESS;\n}\n</code></pre>"},{"location":"dev/tutorial/","title":"A gentle introduction to (sca)LAPACK(e)","text":"<p>Info</p> <p>There are not a lot of info about scaLAPACK on the internet, except for some rare blog posts or stackoverflow questions. The most complete source of information is the scaLAPACK user gide.</p> <p>Sadly, an extensive list of the functions provided by scaLAPACK is not easy to find (thought many of them are mentioned in this section in the aformentioned document) and the \"best\" documentation to know the use of each argument is the source code of the reference implementation (which is probably not the best idea). That being said, this document tries to help you entering this (rather obscure?) world.</p> <p>xxx.</p>"},{"location":"dev/tutorial/#sources","title":"Sources","text":"<ul> <li>https://info.gwdg.de/wiki/doku.php?id=wiki:hpc:scalapack</li> <li>https://gitlab.phys.ethz.ch/hpcse_fs15/lecture</li> <li>https://andyspiros.wordpress.com/2011/07/08/an-example-of-blacs-with-c/</li> </ul>"}]}